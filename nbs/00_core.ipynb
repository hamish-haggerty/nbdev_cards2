{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def C_z1z2(z1norm,z1norm_2,z2norm,z2norm_2,bs):\n",
    "    \"\"\"Input: bs*d shaped inputs z, which are bs-samples from d-dim random variables.\n",
    "       Return: 0.5*corr(z1norm,z1norm_2) + 0.5*corr(z2norm,z2norm_2)\n",
    "       which will be d*d dimensional, as sum of cross correlation matrices.\n",
    "    \"\"\"\n",
    "    \n",
    "    C1 =  (z1norm.T @ z2norm_2) / bs\n",
    "    C2 = (z1norm_2.T @ z2norm) / bs\n",
    "    return C1.pow(2) + 0.5*C2.pow(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, suppose $bs=32$ and $d=100$. Then we can verify that the output will be $d \\times d$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,d = 32,100\n",
    "z1norm=torch.rand(32,100)\n",
    "z1norm_2=torch.rand(32,100)\n",
    "z2norm=torch.rand(32,100)\n",
    "z2norm_2=torch.rand(32,100)\n",
    "\n",
    "test_eq(C_z1z2(z1norm,z1norm_2,z2norm,z2norm_2,bs).shape, (d,d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Max_Corr(nn.Module):\n",
    "    \"\"\"A pair of feedforward nets with one hidden layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(ps,ps) #fc1 and fc2 belong to the first net\n",
    "        self.fc2 = nn.Linear(ps,ps)\n",
    "\n",
    "        self.fc3 = nn.Linear(ps,ps)#fc3 and fc4 belong to the first net\n",
    "        self.fc4 = nn.Linear(ps,ps)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "\n",
    "        x=self.sigmoid(self.fc1(x)) #use sigmoid on the first net\n",
    "        x=self.fc2(x)\n",
    "       \n",
    "        y=self.relu(self.fc3(y)) #use relu on the second net\n",
    "        y=self.fc4(y)\n",
    "\n",
    "        return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Cdiff_Sup:\n",
    "    \n",
    "    def __init__(self,I,inner_steps,bs):\n",
    "        \n",
    "        self.I=I\n",
    "        self.inner_steps=inner_steps\n",
    "        self.bs=bs\n",
    "        self.max_corr = Max_Corr()\n",
    "        if device == 'cuda':\n",
    "            self.max_corr.cuda()\n",
    "        \n",
    "    def inner_step(self,z1norm,z2norm):\n",
    "    \n",
    "        max_corr=self.max_corr\n",
    "        I=self.I\n",
    "        bs=self.bs\n",
    "        inner_steps=self.inner_steps\n",
    "\n",
    "        z1norm=z1norm.detach()\n",
    "        z2norm=z2norm.detach()\n",
    "\n",
    "        max_corr = self.max_corr\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.Adam(list(max_corr.parameters()),lr=0.001)\n",
    "        for i in range(inner_steps):\n",
    "            z1norm_2,z2norm_2=max_corr(z1norm,z2norm)        \n",
    "            assert (z1norm_2.shape,z2norm_2.shape) == (z1norm.shape,z2norm.shape)\n",
    "\n",
    "            cdiff_2 = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
    "            inner_loss=-1*(cdiff_2*(1-I)).mean()\n",
    "            optimizer.zero_grad()\n",
    "            inner_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        for p in max_corr.parameters():\n",
    "            p.requires_grad=False\n",
    "            \n",
    "        return max_corr\n",
    "    \n",
    "    def __call__(self,z1norm,z2norm):\n",
    "        \n",
    "            max_corr =  self.inner_step(z1norm,z2norm)\n",
    "            z1norm_2,z2norm_2 = max_corr(z1norm,z2norm)\n",
    "            cdiff_sup = C_z1z2(z1norm=z1norm,z1norm_2=z1norm_2,z2norm=z2norm,z2norm_2=z2norm_2,bs=bs)\n",
    "    \n",
    "            return cdiff_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## | hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
